{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Klasyfikacja Ryzyka Cukrzycy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Autorzy/Autor",
        "IMI\u0118 NAZWISKO (numer indeksu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Streszczenie",
        "Niniejszy projekt ma na celu zbudowanie i por\u00f3wnanie modeli klasyfikacyjnych do przewidywania ryzyka cukrzycy na podstawie danych zdrowotnych i demograficznych. Wykorzystane zostan\u0105 dane z badania BRFSS2015. W ramach projektu przeprowadzono wst\u0119pn\u0105 analiz\u0119 danych, transformacje, identyfikacj\u0119 i obs\u0142ug\u0119 brak\u00f3w danych oraz obserwacji odstaj\u0105cych. Zastosowano trzy algorytmy klasyfikacyjne: K-Nearest Neighbors (KNN), Drzewo Decyzyjne oraz Las Losowy (Random Forest), a tak\u017ce model hybrydowy. Modele zostan\u0105 ocenione przy u\u017cyciu metryk takich jak Accuracy, F1-Score, AUC oraz macierz konfuzji. Przedstawione zostan\u0105 r\u00f3wnie\u017c przyk\u0142ady u\u017cycia wytrenowanych modeli na nowych, nieznanych obserwacjach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## S\u0142owa kluczowe",
        "Cukrzyca, Klasyfikacja, Machine Learning, KNN, Drzewo Decyzyjne, Random Forest, Analiza danych, Walidacja krzy\u017cowa, SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wprowadzenie",
        "Cukrzyca jest powa\u017cnym problemem zdrowotnym na ca\u0142ym \u015bwiecie, prowadz\u0105cym do wielu powik\u0142a\u0144, takich jak choroby serca, udar, niewydolno\u015b\u0107 nerek czy utrata wzroku. Wczesne wykrycie i interwencja s\u0105 kluczowe dla zarz\u0105dzania chorob\u0105 i poprawy jako\u015bci \u017cycia pacjent\u00f3w. Rozw\u00f3j modeli predykcyjnych opartych na danych medycznych i behawioralnych mo\u017ce znacz\u0105co przyczyni\u0107 si\u0119 do identyfikacji os\u00f3b zagro\u017conych, umo\u017cliwiaj\u0105c wdro\u017cenie dzia\u0142a\u0144 zapobiegawczych. W tym projekcie skupiamy si\u0119 na zastosowaniu algorytm\u00f3w uczenia maszynowego do klasyfikacji ryzyka cukrzycy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Przedmiot badania i Cel",
        "**Przedmiot badania:** Zbi\u00f3r danych 'diabetes_012_health_indicators_BRFSS2015.csv', zawieraj\u0105cy dane zdrowotne i demograficzne ankietowanych os\u00f3b z badania BRFSS (Behavioral Risk Factor Surveillance System) z 2015 roku, z informacj\u0105 o statusie cukrzycowym (brak cukrzycy, pre-cukrzyca, cukrzyca).\\n",
        "Dla uproszczenia problemu klasyfikacji, zmienna docelowa zostanie przekszta\u0142cona na binarn\u0105, gdzie 0 oznacza brak cukrzycy, a 1 oznacza pre-cukrzyc\u0119 lub cukrzyc\u0119. Pozosta\u0142e zmienne to wska\u017aniki zdrowotne i demograficzne. Poni\u017cej przedstawiono list\u0119 zmiennych obja\u015bniaj\u0105cych.\\n",
        "**Cel:** G\u0142\u00f3wnym celem projektu jest opracowanie i ocena modeli klasyfikacyjnych, kt\u00f3re b\u0119d\u0105 w stanie skutecznie przewidywa\u0107 ryzyko wyst\u0105pienia cukrzycy (lub jej braku) na podstawie dost\u0119pnych zmiennych. Dodatkowo, projekt ma na celu por\u00f3wnanie wydajno\u015bci r\u00f3\u017cnych algorytm\u00f3w uczenia maszynowego oraz zrozumienie, kt\u00f3re zmienne maj\u0105 najwi\u0119kszy wp\u0142yw na predykcj\u0119 ryzyka cukrzycy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wst\u0119pna analiza danych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Opis danych i zmiennych",
        "Wykorzystany zbi\u00f3r danych `diabetes_012_health_indicators_BRFSS2015.csv` pochodzi z badania BRFSS 2015, zbieraj\u0105cego dane dotycz\u0105ce zdrowia doros\u0142ych Amerykan\u00f3w. Zawiera on 22 zmienne, w tym zmienn\u0105 docelow\u0105 `Diabetes_012`, kt\u00f3ra klasyfikuje status cukrzycowy:\\n",
        "- 0: brak cukrzycy\\n",
        "- 1: pre-cukrzyca\\n",
        "- 2: cukrzyca\\n",
        "Dla uproszczenia problemu klasyfikacji, zmienna docelowa zostanie przekszta\u0142cona na binarn\u0105, gdzie 0 oznacza brak cukrzycy, a 1 oznacza pre-cukrzyc\u0119 lub cukrzyc\u0119. Pozosta\u0142e zmienne to wska\u017aniki zdrowotne i demograficzne. Poni\u017cej przedstawiono list\u0119 zmiennych obja\u015bniaj\u0105cych:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wczytanie danych\n",
        "df = pd.read_csv(\"diabetes_012_health_indicators_BRFSS2015.csv\")\n",
        "\n",
        "# Przekszta\u0142cenie zmiennej docelowej na binarn\u0105\n",
        "df['Diabetes_012'] = df['Diabetes_012'].replace({1: 1, 2: 1})\n",
        "\n",
        "print(\"Zmienna docelowa:\", \"Diabetes_012\")\n",
        "print(\"Zmienne obja\u015bniaj\u0105ce:\", list(df.columns.difference(['Diabetes_012'])))\n",
        "print(\"\\nKszta\u0142t zbioru danych:\", df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Statystyki opisowe",
        "Poni\u017cej przedstawiono statystyki opisowe dla ka\u017cdej zmiennej, w tym \u015bredni\u0105, median\u0119 (50% kwantyl), minimum, maksimum, odchylenie standardowe oraz sko\u015bno\u015b\u0107. Sko\u015bno\u015b\u0107 wskazuje na asymetri\u0119 rozk\u0142adu danych; warto\u015bci bliskie 0 oznaczaj\u0105 rozk\u0142ad symetryczny, warto\u015bci dodatnie sko\u015bno\u015b\u0107 prawostronn\u0105, a ujemne lewostronn\u0105."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "desc = df.describe().T\n",
        "desc[\"skewness\"] = df.skew()\n",
        "print(desc[[\"mean\", \"50%\", \"min\", \"max\", \"std\", \"skewness\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Podstawowa wizualizacja danych",
        "Wizualizacje pomagaj\u0105 zrozumie\u0107 rozk\u0142ad danych i relacje mi\u0119dzy zmiennymi. Poni\u017cej przedstawiono rozk\u0142ad zmiennej docelowej oraz histogramy dla wybranych zmiennych numerycznych, aby zilustrowa\u0107 ich rozk\u0142ady."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rozk\u0142ad klas zmiennej docelowej\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x=\"Diabetes_012\", data=df)\n",
        "plt.title(\"Rozk\u0142ad klas zmiennej docelowej (0: Brak cukrzycy, 1: Cukrzyca/Pre-cukrzyca)\")\n",
        "plt.xlabel(\"Status Cukrzycowy\")\n",
        "plt.ylabel(\"Liczba obserwacji\")\n",
        "plt.xticks([0, 1], ['Brak cukrzycy', 'Cukrzyca/Pre-cukrzyca'])\n",
        "plt.show()\n",
        "\n",
        "# Histogramy dla wybranych zmiennych numerycznych\n",
        "num_cols = ['BMI', 'Age', 'MentHlth', 'PhysHlth', 'Education', 'Income']\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, col in enumerate(num_cols):\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    sns.histplot(df[col], kde=True)\n",
        "    plt.title(f'Rozk\u0142ad zmiennej: {col}')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Boxploty dla wybranych zmiennych numerycznych w zale\u017cno\u015bci od statusu cukrzycowego\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, col in enumerate(num_cols):\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    sns.boxplot(x='Diabetes_012', y=col, data=df)\n",
        "    plt.title(f'Boxplot {col} wg statusu cukrzycy')\n",
        "    plt.xticks([0, 1], ['Brak cukrzycy', 'Cukrzyca/Pre-cukrzyca'])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Braki danych i obserwacje odstaj\u0105ce",
        "Przed przyst\u0105pieniem do modelowania kluczowe jest sprawdzenie brak\u00f3w danych i obs\u0142ugi obserwacji odstaj\u0105cych. Brakuj\u0105ce warto\u015bci mog\u0105 prowadzi\u0107 do b\u0142\u0119dnych wynik\u00f3w, a obserwacje odstaj\u0105ce mog\u0105 zniekszta\u0142ca\u0107 modele. \\n",
        "\\n",
        "**Braki danych:** Sprawdzamy, czy w zbiorze danych wyst\u0119puj\u0105 brakuj\u0105ce warto\u015bci. Je\u015bli tak, w zale\u017cno\u015bci od ich liczby i charakteru, mo\u017cna je uzupe\u0142ni\u0107 (np. \u015bredni\u0105, median\u0105, mod\u0105) lub usun\u0105\u0107 wiersze/kolumny zawieraj\u0105ce braki. W tym zbiorze danych nie ma brakuj\u0105cych warto\u015bci, co upraszcza preprocessing.\\n",
        "\\n",
        "**Obserwacje odstaj\u0105ce:** Obserwacje odstaj\u0105ce to punkty danych, kt\u00f3re znacznie odbiegaj\u0105 od wi\u0119kszo\u015bci danych. Mo\u017cna je identyfikowa\u0107 za pomoc\u0105 metod statystycznych (np. IQR) lub wizualizacji (np. boxploty). W przypadku wielu zmiennych z potencjalnymi warto\u015bciami odstaj\u0105cymi, takimi jak BMI, MentHlth czy PhysHlth, skalowanie danych (np. MinMaxScaler) oraz ewentualne transformacje (np. logarytmowanie) pomagaj\u0105 zmniejszy\u0107 ich wp\u0142yw na modele, zw\u0142aszcza te wra\u017cliwe na skal\u0119 zmiennych (np. KNN)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Liczba brakuj\u0105cych warto\u015bci w ka\u017cdej kolumnie:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"\\nBrak brakuj\u0105cych warto\u015bci w zbiorze danych.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Transformacje danych (Skalowanie i Logarytmowanie)",
        "**Logarytmowanie:** Zmienne o sko\u015bnym rozk\u0142adzie (np. `BMI`, `MentHlth`, `PhysHlth`, `Age`, `Education`, `Income`) mog\u0105 skorzysta\u0107 z transformacji logarytmicznej, kt\u00f3ra pomaga zmniejszy\u0107 sko\u015bno\u015b\u0107 i sprowadzi\u0107 rozk\u0142ad do bardziej zbli\u017conego do normalnego. U\u017cyto `np.log1p`, kt\u00f3ra oblicza `log(1+x)`, co jest przydatne, gdy dane zawieraj\u0105 zera.\\n",
        "\\n",
        "**Skalowanie:** Algorytmy uczenia maszynowego oparte na odleg\u0142o\u015bci (np. KNN) s\u0105 wra\u017cliwe na skal\u0119 zmiennych. `MinMaxScaler` skaluje ka\u017cd\u0105 zmienn\u0105 do zakresu [0, 1], co zapewnia, \u017ce \u017cadna zmienna nie dominuje nad innymi ze wzgl\u0119du na jej wi\u0119kszy zakres warto\u015bci."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Zmienne do logarytmowania (wybrane na podstawie analizy sko\u015bno\u015bci)\n",
        "log_cols = ['BMI', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income']\n",
        "for col in log_cols:\n",
        "    if col in df.columns:\n",
        "        df[col] = np.log1p(df[col])\n",
        "        print(f\"Zmienna {col} zosta\u0142a zlogarytmowana.\")\n",
        "\n",
        "# Skalowanie danych\n",
        "scaler = MinMaxScaler()\n",
        "X = df.drop('Diabetes_012', axis=1)\n",
        "y = df['Diabetes_012']\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "print(\"Dane zosta\u0142y przeskalowane przy u\u017cyciu MinMaxScaler.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Macierz korelacji zmiennych",
        "Macierz korelacji pokazuje si\u0142\u0119 i kierunek liniowych zale\u017cno\u015bci mi\u0119dzy parami zmiennych. Wysoka korelacja mi\u0119dzy zmiennymi obja\u015bniaj\u0105cymi (multicollinearity) mo\u017ce wp\u0142ywa\u0107 na stabilno\u015b\u0107 i interpretowalno\u015b\u0107 niekt\u00f3rych modeli. Dodatkowo, korelacja zmiennych obja\u015bniaj\u0105cych ze zmienn\u0105 docelow\u0105 wskazuje na ich potencjaln\u0105 wa\u017cno\u015b\u0107 w przewidywaniu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 12))\n",
        "correlation_matrix = df.corr()\n",
        "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Macierz korelacji zmiennych\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Opis metod"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Podzia\u0142 danych (Treningowe/Testowe)",
        "Zbi\u00f3r danych zosta\u0142 podzielony na podzbi\u00f3r treningowy (80%) i testowy (20%). Podzbi\u00f3r treningowy jest u\u017cywany do uczenia modeli, natomiast podzbi\u00f3r testowy s\u0142u\u017cy do oceny wydajno\u015bci wytrenowanych modeli na niewidzianych danych, co pozwala oszacowa\u0107 ich zdolno\u015b\u0107 do generalizacji. Zastosowano `stratify=y` aby zachowa\u0107 proporcje klas zmiennej docelowej w obu podzbiorach, co jest kluczowe w przypadku niezbalansowanych klas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(\"Kszta\u0142t zbioru treningowego X:\", X_train.shape)\n",
        "print(\"Kszta\u0142t zbioru testowego X:\", X_test.shape)\n",
        "print(\"Kszta\u0142t zbioru treningowego y:\", y_train.shape)\n",
        "print(\"Kszta\u0142t zbioru testowego y:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Obs\u0142uga niezbalansowanych danych - SMOTE",
        "Zauwa\u017cono, \u017ce klasy w zmiennej docelowej s\u0105 niezbalansowane (znacznie wi\u0119cej obserwacji bez cukrzycy ni\u017c z cukrzyc\u0105). Niezbalansowane klasy mog\u0105 prowadzi\u0107 do modeli, kt\u00f3re s\u0105 biasowe w stron\u0119 klasy wi\u0119kszo\u015bciowej i s\u0142abo radz\u0105 sobie z przewidywaniem klasy mniejszo\u015bciowej. Aby temu zaradzi\u0107, zastosowano metod\u0119 **SMOTE (Synthetic Minority Over-sampling Technique)** na zbiorze treningowym. SMOTE tworzy syntetyczne pr\u00f3bki klasy mniejszo\u015bciowej na podstawie istniej\u0105cych pr\u00f3bek, co pomaga wyr\u00f3wna\u0107 rozk\u0142ad klas i poprawi\u0107 wydajno\u015b\u0107 modelu dla klasy mniejszo\u015bciowej."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Rozk\u0142ad klas przed SMOTE:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"\\nRozk\u0142ad klas po SMOTE:\")\n",
        "print(y_train_res.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modele Klasyfikacyjne"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### K-Nearest Neighbors (KNN)",
        "**Opis:** KNN to algorytm klasyfikacyjny oparty na odleg\u0142o\u015bci. Klasyfikuje now\u0105 obserwacj\u0119 na podstawie wi\u0119kszo\u015bci g\u0142os\u00f3w jej 'k' najbli\u017cszych s\u0105siad\u00f3w w przestrzeni cech. Dzia\u0142a na zasadzie 'leniwego uczenia' (lazy learning), co oznacza, \u017ce nie buduje modelu podczas fazy treningowej, a jedynie przechowuje dane treningowe i wykonuje obliczenia dopiero w momencie predykcji.  Warto\u015b\u0107 `k` (liczba s\u0105siad\u00f3w) jest kluczowym hiperparametrem. \\n",
        "**Referencje:** Fix, E., & Hodges, J. L. (1951). *Discriminatory Analysis. Nonparametric Discrimination: Consistency Properties.* USAF School of Aviation Medicine, Randolph Field, Texas.  (Cho\u0107 formalnie praca jest z 1951, koncepcja KNN by\u0142a rozwijana w latach 60. i 70. przez m.in. T. Covera i P. Hart'a)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_knn = KNeighborsClassifier(n_neighbors=5)\n",
        "model_knn.fit(X_train_res, y_train_res)\n",
        "y_pred_knn = model_knn.predict(X_test)\n",
        "y_proba_knn = model_knn.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"K-Nearest Neighbors (KNN) - Macierz Konfuzji:\")\n",
        "print(confusion_matrix(y_test, y_pred_knn))\n",
        "print(\"\\nRaport klasyfikacyjny KNN:\")\n",
        "print(classification_report(y_test, y_pred_knn))\n",
        "print(\"AUC KNN:\", roc_auc_score(y_test, y_proba_knn))\n",
        "print(\"Accuracy KNN:\", accuracy_score(y_test, y_pred_knn))\n",
        "print(\"F1-Score KNN:\", f1_score(y_test, y_pred_knn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Drzewo Decyzyjne (Decision Tree)",
        "**Opis:** Drzewo decyzyjne to model klasyfikacyjny, kt\u00f3ry konstruuje drzewo, gdzie ka\u017cdy w\u0119ze\u0142 wewn\u0119trzny reprezentuje test na atrybucie, ka\u017cda ga\u0142\u0105\u017a reprezentuje wynik testu, a ka\u017cdy li\u015b\u0107 (w\u0119ze\u0142 ko\u0144cowy) reprezentuje etykiet\u0119 klasy. Proces budowy drzewa polega na rekurencyjnym dzieleniu danych na podgrupy na podstawie cech, kt\u00f3re najlepiej rozdzielaj\u0105 klasy. \\n",
        "**Referencje:** Quinlan, J. R. (1986). *Induction of decision trees.* Machine learning, 1(1), 81-106."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dt = DecisionTreeClassifier(random_state=42)\n",
        "model_dt.fit(X_train_res, y_train_res)\n",
        "y_pred_dt = model_dt.predict(X_test)\n",
        "y_proba_dt = model_dt.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Drzewo Decyzyjne - Macierz Konfuzji:\")\n",
        "print(confusion_matrix(y_test, y_pred_dt))\n",
        "print(\"\\nRaport klasyfikacyjny Drzewa Decyzyjnego:\")\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "print(\"AUC Drzewa Decyzyjnego:\", roc_auc_score(y_test, y_proba_dt))\n",
        "print(\"Accuracy Drzewa Decyzyjnego:\", accuracy_score(y_test, y_pred_dt))\n",
        "print(\"F1-Score Drzewa Decyzyjnego:\", f1_score(y_test, y_pred_dt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Wizualizacja Drzewa Klasyfikacji (Przyk\u0142adowe ma\u0142e drzewo)",
        "Dla lepszego zrozumienia dzia\u0142ania drzewa decyzyjnego, poni\u017cej przedstawiono wizualizacj\u0119 ma\u0142ego drzewa zbudowanego na podzbiorze danych. Pozwala to na podgl\u0105d regu\u0142 decyzyjnych."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(model_dt, feature_names=X.columns, class_names=['Brak cukrzycy', 'Cukrzyca'], filled=True, rounded=True, fontsize=8, max_depth=3)\n",
        "plt.title(\"Przyk\u0142adowe Drzewo Decyzyjne (max_depth=3)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Las Losowy (Random Forest)",
        "**Opis:** Random Forest to algorytm zespo\u0142owy (ensemble learning), kt\u00f3ry buduje wiele drzew decyzyjnych podczas treningu i wyprowadza klas\u0119, kt\u00f3ra jest mod\u0105 klas (klasyfikacja) lub \u015bredni\u0105 predykcji (regresja) poszczeg\u00f3lnych drzew. Kluczow\u0105 ide\u0105 jest losowe wybieranie podzbior\u00f3w cech i podpr\u00f3bek danych treningowych dla ka\u017cdego drzewa, co zwi\u0119ksza r\u00f3\u017cnorodno\u015b\u0107 i redukuje wariancj\u0119, prowadz\u0105c do lepszej generalizacji. \\n",
        "**Referencje:** Breiman, L. (2001). *Random Forests.* Machine Learning, 45(1), 5-32."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_rf = RandomForestClassifier(random_state=42)\n",
        "model_rf.fit(X_train_res, y_train_res)\n",
        "y_pred_rf = model_rf.predict(X_test)\n",
        "y_proba_rf = model_rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Random Forest - Macierz Konfuzji:\")\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "print(\"\\nRaport klasyfikacyjny Random Forest:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print(\"AUC Random Forest:\", roc_auc_score(y_test, y_proba_rf))\n",
        "print(\"Accuracy Random Forest:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"F1-Score Random Forest:\", f1_score(y_test, y_pred_rf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Model Hybrydowy (Ensemble - \u015arednia Wa\u017cona Prawdopodobie\u0144stw)",
        "**Opis:** Model hybrydowy \u0142\u0105czy predykcje z wielu modeli bazowych w celu uzyskania lepszej og\u00f3lnej wydajno\u015bci ni\u017c pojedynczy model. W tym przypadku zastosowano proste u\u015brednianie prawdopodobie\u0144stw przewidywanych przez ka\u017cdy z trzech modeli (KNN, Drzewo Decyzyjne, Random Forest). Mo\u017cna r\u00f3wnie\u017c zastosowa\u0107 \u015bredni\u0105 wa\u017con\u0105, je\u015bli z eksperyment\u00f3w wynika, \u017ce niekt\u00f3re modele s\u0105 bardziej wiarygodne. Klasyfikacja odbywa si\u0119 poprzez zaokr\u0105glenie \u015bredniego prawdopodobie\u0144stwa do najbli\u017cszej liczby ca\u0142kowitej (0 lub 1). \\n",
        "**Referencje:** Rokach, L. (2010). *Ensemble-based classifiers*. The Data Mining and Knowledge Discovery Handbook, 193-219. (Og\u00f3lna koncepcja modeli zespo\u0142owych)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Przewidywanie prawdopodobie\u0144stw dla wszystkich modeli\n",
        "y_proba_knn = model_knn.predict_proba(X_test)[:, 1]\n",
        "y_proba_dt = model_dt.predict_proba(X_test)[:, 1]\n",
        "y_proba_rf = model_rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Stworzenie modelu hybrydowego (u\u015brednienie prawdopodobie\u0144stw)\n",
        "y_proba_hybrid = (y_proba_knn + y_proba_dt + y_proba_rf) / 3\n",
        "y_pred_hybrid = (y_proba_hybrid > 0.5).astype(int)\n",
        "\n",
        "print(\"Model Hybrydowy - Macierz Konfuzji:\")\n",
        "print(confusion_matrix(y_test, y_pred_hybrid))\n",
        "print(\"\\nRaport klasyfikacyjny Modelu Hybrydowego:\")\n",
        "print(classification_report(y_test, y_pred_hybrid))\n",
        "print(\"AUC Modelu Hybrydowego:\", roc_auc_score(y_test, y_proba_hybrid))\n",
        "print(\"Accuracy Modelu Hybrydowego:\", accuracy_score(y_test, y_pred_hybrid))\n",
        "print(\"F1-Score Modelu Hybrydowego:\", f1_score(y_test, y_pred_hybrid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Wa\u017cno\u015b\u0107 zmiennych (Feature Importance)",
        "Analiza wa\u017cno\u015bci zmiennych pozwala zidentyfikowa\u0107, kt\u00f3re cechy maj\u0105 najwi\u0119kszy wp\u0142yw na predykcj\u0119 modelu. Jest to szczeg\u00f3lnie przydatne w przypadku modeli opartych na drzewach, takich jak Random Forest, kt\u00f3re naturalnie dostarczaj\u0105 informacji o wa\u017cno\u015bci cech. Poni\u017cej przedstawiono tabel\u0119 z wa\u017cno\u015bci\u0105 zmiennych dla modelu Random Forest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': model_rf.feature_importances_})\n",
        "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
        "print(\"Tabela z wa\u017cno\u015bci\u0105 zmiennych (Random Forest):\")\n",
        "print(feature_importances)\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importances)\n",
        "plt.title('Wa\u017cno\u015b\u0107 Zmiennych (Random Forest)')\n",
        "plt.xlabel('Wa\u017cno\u015b\u0107')\n",
        "plt.ylabel('Zmienna')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rezultaty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Por\u00f3wnanie metryk modeli",
        "Poni\u017cej przedstawiono podsumowanie kluczowych metryk (Accuracy, F1-Score, AUC) dla wszystkich wytrenowanych modeli. Pozwala to na bezpo\u015brednie por\u00f3wnanie ich wydajno\u015bci."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = pd.DataFrame({\n",
        "    'Model': ['KNN', 'Decision Tree', 'Random Forest', 'Hybrid Model'],\n",
        "    'Accuracy': [\n",
        "        accuracy_score(y_test, y_pred_knn),\n",
        "        accuracy_score(y_test, y_pred_dt),\n",
        "        accuracy_score(y_test, y_pred_rf),\n",
        "        accuracy_score(y_test, y_pred_hybrid)\n",
        "    ],\n",
        "    'F1-Score': [\n",
        "        f1_score(y_test, y_pred_knn),\n",
        "        f1_score(y_test, y_pred_dt),\n",
        "        f1_score(y_test, y_pred_rf),\n",
        "        f1_score(y_test, y_pred_hybrid)\n",
        "    ],\n",
        "    'AUC': [\n",
        "        roc_auc_score(y_test, y_proba_knn),\n",
        "        roc_auc_score(y_test, y_proba_dt),\n",
        "        roc_auc_score(y_test, y_proba_rf),\n",
        "        roc_auc_score(y_test, y_proba_hybrid)\n",
        "    ]\n",
        "})\n",
        "print(\"Podsumowanie wydajno\u015bci modeli:\")\n",
        "print(results.set_index('Model'))\n",
        "\n",
        "# Wizualizacja ROC Curve dla wszystkich modeli\n",
        "plt.figure(figsize=(10, 8))\n",
        "ax = plt.gca()\n",
        "RocCurveDisplay.from_estimator(model_knn, X_test, y_test, ax=ax, name='KNN')\n",
        "RocCurveDisplay.from_estimator(model_dt, X_test, y_test, ax=ax, name='Decision Tree')\n",
        "RocCurveDisplay.from_estimator(model_rf, X_test, y_test, ax=ax, name='Random Forest')\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Random Guess')\n",
        "plt.title('Krzywe ROC dla Modeli Klasyfikacyjnych')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Spos\u00f3b walidacji (Walidacja Krzy\u017cowa - Cross-Validation)",
        "Walidacja krzy\u017cowa, w szczeg\u00f3lno\u015bci k-krotna walidacja krzy\u017cowa (k-fold cross-validation), jest robustn\u0105 metod\u0105 oceny wydajno\u015bci modelu i pomaga unikn\u0105\u0107 przeuczenia (overfittingu). Zbi\u00f3r danych jest dzielony na 'k' podzbior\u00f3w. Model jest trenowany 'k' razy, za ka\u017cdym razem u\u017cywaj\u0105c innego podzbioru jako zbioru walidacyjnego, a pozosta\u0142e 'k-1' podzbior\u00f3w jako zbioru treningowego. Wyniki s\u0105 nast\u0119pnie u\u015bredniane. W ten spos\u00f3b ocena modelu jest mniej zale\u017cna od konkretnego podzia\u0142u danych na zbi\u00f3r treningowy i testowy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Wyniki walidacji krzy\u017cowej (5-krotna) - Accuracy:\")\n",
        "cv_scores_knn = cross_val_score(model_knn, X_scaled, y, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "print(f\"KNN: {cv_scores_knn.mean():.4f} (+/- {cv_scores_knn.std():.4f})\")\n",
        "\n",
        "cv_scores_dt = cross_val_score(model_dt, X_scaled, y, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "print(f\"Decision Tree: {cv_scores_dt.mean():.4f} (+/- {cv_scores_dt.std():.4f})\")\n",
        "\n",
        "cv_scores_rf = cross_val_score(model_rf, X_scaled, y, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "print(f\"Random Forest: {cv_scores_rf.mean():.4f} (+/- {cv_scores_rf.std():.4f})\")\n",
        "\n",
        "# Dla modelu hybrydowego walidacja krzy\u017cowa jest bardziej z\u0142o\u017cona, wymaga niestandardowej funkcji lub iteracji\n",
        "# Poni\u017cej przyk\u0142ad prostej walidacji krzy\u017cowej dla hybrydy, jednak dla pe\u0142nej oceny zaleca si\u0119 bardziej zaawansowane podej\u015bcie ensemble learning cross-validation.\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "hybrid_cv_scores = []\n",
        "for train_index, val_index in kf.split(X_scaled):\n",
        "    X_train_fold, X_val_fold = X_scaled.iloc[train_index], X_scaled.iloc[val_index]\n",
        "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    # Zastosowanie SMOTE na danych treningowych w ka\u017cdej fa\u0142dzie\n",
        "    X_train_res_fold, y_train_res_fold = sm.fit_resample(X_train_fold, y_train_fold)\n",
        "\n",
        "    model_knn.fit(X_train_res_fold, y_train_res_fold)\n",
        "    model_dt.fit(X_train_res_fold, y_train_res_fold)\n",
        "    model_rf.fit(X_train_res_fold, y_train_res_fold)\n",
        "\n",
        "    y_proba_knn_fold = model_knn.predict_proba(X_val_fold)[:, 1]\n",
        "    y_proba_dt_fold = model_dt.predict_proba(X_val_fold)[:, 1]\n",
        "    y_proba_rf_fold = model_rf.predict_proba(X_val_fold)[:, 1]\n",
        "\n",
        "    y_proba_hybrid_fold = (y_proba_knn_fold + y_proba_dt_fold + y_proba_rf_fold) / 3\n",
        "    y_pred_hybrid_fold = (y_proba_hybrid_fold > 0.5).astype(int)\n",
        "    hybrid_cv_scores.append(accuracy_score(y_val_fold, y_pred_hybrid_fold))\n",
        "\n",
        "hybrid_cv_scores = np.array(hybrid_cv_scores)\n",
        "print(f\"Hybrid Model: {hybrid_cv_scores.mean():.4f} (+/- {hybrid_cv_scores.std():.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Przyk\u0142ady u\u017cycia modeli na nieznanych obserwacjach",
        "Poni\u017cej przedstawiono przyk\u0142ady predykcji dla dw\u00f3ch sztucznie stworzonych obserwacji: jednej reprezentuj\u0105cej osob\u0119 zdrow\u0105 o niskim ryzyku cukrzycy, a drugiej osob\u0119 z czynnikami ryzyka. Dane wej\u015bciowe s\u0105 najpierw logarytmowane (dla wybranych zmiennych), a nast\u0119pnie skalowane przy u\u017cyciu tego samego `MinMaxScaler`, kt\u00f3ry zosta\u0142 dopasowany do danych treningowych. Dzi\u0119ki temu, modele mog\u0105 dokonywa\u0107 predykcji na danych o podobnym zakresie i rozk\u0142adzie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Dane wej\u015bciowe dla osoby zdrowej ===\")\n",
        "sample_healthy = pd.DataFrame([{\n",
        "    'HighBP': 0, 'HighChol': 0, 'CholCheck': 1, 'BMI': 22, 'Smoker': 0, 'Stroke': 0,\n",
        "    'HeartDiseaseorAttack': 0, 'PhysActivity': 1, 'Fruits': 1, 'Veggies': 1,\n",
        "    'HvyAlcoholConsump': 0, 'AnyHealthcare': 1, 'NoDocbcCost': 0, 'GenHlth': 2,\n",
        "    'MentHlth': 0, 'PhysHlth': 0, 'DiffWalk': 0, 'Sex': 0, 'Age': 6, 'Education': 6, 'Income': 8\n",
        "}], columns=X.columns) # Wa\u017cne aby kolumny zgadza\u0142y si\u0119 z X.columns\n",
        "\n",
        "print(\"Nieprzetworzone dane:\")\n",
        "for col, val in sample_healthy.iloc[0].items():\n",
        "    print(f\"{col}: {np.round(val, 3)}\")\n",
        "\n",
        "sample_healthy_processed = sample_healthy.copy()\n",
        "for col in log_cols:\n",
        "    if col in sample_healthy_processed.columns:\n",
        "        sample_healthy_processed[col] = np.log1p(sample_healthy_processed[col])\n",
        "\n",
        "sample_healthy_scaled = scaler.transform(sample_healthy_processed)\n",
        "\n",
        "print(\"\\nPredykcje dla osoby zdrowej:\")\n",
        "print(f\"KNN przewiduje: {'Cukrzyca' if model_knn.predict(sample_healthy_scaled)[0] == 1 else 'Brak cukrzycy'}\")\n",
        "print(f\"Drzewo Decyzyjne przewiduje: {'Cukrzyca' if model_dt.predict(sample_healthy_scaled)[0] == 1 else 'Brak cukrzycy'}\")\n",
        "print(f\"Random Forest przewiduje: {'Cukrzyca' if model_rf.predict(sample_healthy_scaled)[0] == 1 else 'Brak cukrzycy'}\")\n",
        "\n",
        "proba_hybrid_healthy = (model_knn.predict_proba(sample_healthy_scaled)[:, 1] + \\\n",
        "                      model_dt.predict_proba(sample_healthy_scaled)[:, 1] + \\\n",
        "                      model_rf.predict_proba(sample_healthy_scaled)[:, 1]) / 3\n",
        "print(f\"Model Hybrydowy przewiduje: {'Cukrzyca' if (proba_hybrid_healthy > 0.5)[0] else 'Brak cukrzycy'}\\n\")\n",
        "\n",
        "\n",
        "print(\"=== Dane wej\u015bciowe dla osoby z ryzykiem cukrzycy ===\")\n",
        "sample_risk = pd.DataFrame([{\n",
        "    'HighBP': 1, 'HighChol': 1, 'CholCheck': 1, 'BMI': 35, 'Smoker': 1, 'Stroke': 0,\n",
        "    'HeartDiseaseorAttack': 1, 'PhysActivity': 0, 'Fruits': 0, 'Veggies': 0,\n",
        "    'HvyAlcoholConsump': 0, 'AnyHealthcare': 1, 'NoDocbcCost': 0, 'GenHlth': 4,\n",
        "    'MentHlth': 20, 'PhysHlth': 30, 'DiffWalk': 1, 'Sex': 1, 'Age': 9, 'Education': 4, 'Income': 3\n",
        "}], columns=X.columns)\n",
        "\n",
        "print(\"Nieprzetworzone dane:\")\n",
        "for col, val in sample_risk.iloc[0].items():\n",
        "    print(f\"{col}: {np.round(val, 3)}\")\n",
        "\n",
        "sample_risk_processed = sample_risk.copy()\n",
        "for col in log_cols:\n",
        "    if col in sample_risk_processed.columns:\n",
        "        sample_risk_processed[col] = np.log1p(sample_risk_processed[col])\n",
        "\n",
        "sample_risk_scaled = scaler.transform(sample_risk_processed)\n",
        "\n",
        "print(f\"\\nPredykcje dla osoby z ryzykiem:\")\n",
        "print(f\"KNN przewiduje: {'Cukrzyca' if model_knn.predict(sample_risk_scaled)[0] == 1 else 'Brak cukrzycy'}\")\n",
        "print(f\"Drzewo Decyzyjne przewiduje: {'Cukrzyca' if model_dt.predict(sample_risk_scaled)[0] == 1 else 'Brak cukrzycy'}\")\n",
        "print(f\"Random Forest przewiduje: {'Cukrzyca' if model_rf.predict(sample_risk_scaled)[0] == 1 else 'Brak cukrzycy'}\")\n",
        "\n",
        "proba_hybrid_risk = (model_knn.predict_proba(sample_risk_scaled)[:, 1] + \\\n",
        "                   model_dt.predict_proba(sample_risk_scaled)[:, 1] + \\\n",
        "                   model_rf.predict_proba(sample_risk_scaled)[:, 1]) / 3\n",
        "print(f\"Model Hybrydowy przewiduje: {'Cukrzyca' if (proba_hybrid_risk > 0.5)[0] else 'Brak cukrzycy'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bibliografia",
        "\\* Breiman, L. (2001). *Random Forests.* Machine Learning, 45(1), 5-32.\\n",
        "\\* Fix, E., & Hodges, J. L. (1951). *Discriminatory Analysis. Nonparametric Discrimination: Consistency Properties.* USAF School of Aviation Medicine, Randolph Field, Texas.\\n",
        "\\* Quinlan, J. R. (1986). *Induction of decision trees.* Machine learning, 1(1), 81-106.\\n",
        "\\* Rokach, L. (2010). *Ensemble-based classifiers*. The Data Mining and Knowledge Discovery Handbook, 193-219.\\n",
        "\\* Chawla, N. V., Bowyer, K. W., Hall, L. O., & Kegelmeyer, W. P. (2002). *SMOTE: synthetic minority over-sampling technique*. Journal of artificial intelligence research, 16, 321-357."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}